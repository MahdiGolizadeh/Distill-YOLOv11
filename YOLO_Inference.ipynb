{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23ab1d3a-4ec9-4b81-b0e4-5f3eaf542654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c9a0dc9-0ded-4c25-8eb4-9d09353e9354",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c84c6635-93a8-48d9-840a-8c6ee87ea923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\00.MOTHER_BOXES\\code\\modification\\car.jpg: 480x640 1 car, 114.7ms\n",
      "Speed: 6.1ms preprocess, 114.7ms inference, 19.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "result = model(\"car.jpg\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "249cfdb7-42a7-4145-a839-8f4aa07965c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50bdce47-4441-4c8f-8757-620b57b28bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.models.yolo.detect.predict import DetectionPredictor\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f019fad2-28a0-4df3-8987-3af77ed4176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your model\n",
    "model = YOLO(\"yolo11n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cda074d3-f1d9-464a-8cf5-6640ca8b9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictor directly\n",
    "predictor = DetectionPredictor(overrides={\n",
    "    \"conf\": 0.25,\n",
    "    \"imgsz\": 640,\n",
    "    \"device\": \"cuda\"  # or \"cuda\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4999746-cbb9-47c8-8d6d-090f6fb4e1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.184  Python-3.13.5 torch-2.9.0+cu130 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "# Setup the model (CRITICAL STEP - this is what the Model class does internally)\n",
    "predictor.setup_model(model=model.model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "019c900d-b5d3-4fa8-8bbf-14d86f4e1ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\00.MOTHER_BOXES\\code\\modification\\car.jpg: 640x640 1 car, 61.7ms\n",
      "Speed: 6.7ms preprocess, 61.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mD:\\00.MOTHER_BOXES\\code\\modification\\runs\\detect\\train13\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Now you can use it directly\n",
    "results = predictor(\"car.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d357dfd-604f-4e77-84a2-1e33c9fd0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8fcad2-8077-4d76-bc2e-005acf194e20",
   "metadata": {},
   "source": [
    "preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78814cba-6a54-4ef3-96a4-01cb2b3caa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.engine.predictor import BasePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da767527-1ff5-45be-9ad4-94af6841fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build predictor (this contains YOLO preprocess)\n",
    "predictor = BasePredictor(overrides={\"model\": \"yolo11n.pt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed5dcb37-7b05-468f-97e0-4f4694ad2ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.184  Python-3.13.5 torch-2.9.0+cu130 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "# 3. Manually set up model inside predictor\n",
    "predictor.setup_model(\"yolo11n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88120743-d94e-4764-be87-ff15242c5671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load your JPG image using YOLO’s own loader\n",
    "dataset = predictor.setup_source(\"car.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b70168e8-3d73-4df6-963a-bea32185312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Get raw image from predictor as YOLO sees it\n",
    "paths, im0s, _ = next(iter(predictor.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c11a8bb-15f5-4f11-8512-146f22492896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. NOW apply YOLO’s EXACT preprocess\n",
    "img_tensor = predictor.preprocess(im0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73a11e37-d61d-4118-b810-3da2ebe63728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 640, 640])\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48b6854a-9820-436f-ba44-6a45666328f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictor.model(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a21466f6-9386-40aa-ac6f-0329b8df4319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Tensor, list)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds), type(preds[0]), type(preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83d07ec3-e95e-45b8-a652-3066d52050a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " torch.Size([1, 144, 80, 80]),\n",
       " torch.Size([1, 144, 40, 40]),\n",
       " torch.Size([1, 144, 20, 20]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[1]), preds[1][0].shape, preds[1][1].shape, preds[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fb40c45-0221-47a5-acd8-b9a5cc114a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 84, 8400])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72a0c9d7-2e37-48f3-8b8c-2f28bc6250cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.utils.ops import non_max_suppression\n",
    "from ultralytics.engine.results import Results\n",
    "\n",
    "# 1) apply YOLO's NMS (same used inside AutoBackend)\n",
    "nms_output = non_max_suppression(\n",
    "    preds,\n",
    "    conf_thres=predictor.args.conf,\n",
    "    iou_thres=predictor.args.iou,\n",
    "    max_det=predictor.args.max_det,\n",
    "    classes=None,\n",
    "    agnostic=predictor.args.agnostic_nms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b9bff00-f1c8-4b04-989b-7dd1bdc59282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[231.8356, 260.1294, 584.2322, 420.9265,   0.8156,   2.0000]], device='cuda:0')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dab0829a-89f1-4b43-ba12-065ec6977fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.7\n",
      "300\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(predictor.args.conf, predictor.args.iou, predictor.args.max_det, predictor.args.agnostic_nms, sep= \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9123e60-9d0c-40bc-89b1-31ebffa5adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Construct YOLO Results objects for each image\n",
    "results = [\n",
    "    Results(\n",
    "        orig_img=im0s[i],\n",
    "        path=paths[i],\n",
    "        names=predictor.model.names,\n",
    "        boxes=nms_output[i]\n",
    "    )\n",
    "    for i in range(len(nms_output))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b3b61d2-3fe9-4a4e-b5b9-f0852563c039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1530, 2048, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im0s[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b2ccbae-a8d7-4d53-b970-cbff5cc039d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "\n",
    "# Your raw NMS output\n",
    "detections = [torch.tensor([[231.8356, 260.1294, 584.2322, 420.9265, 0.8156, 2.0000]], device='cuda:0')]\n",
    "\n",
    "# Load your image\n",
    "img = cv2.imread(\"car.jpg\")\n",
    "img = cv2.resize(img, (640, 640))\n",
    "# Loop through detections\n",
    "for det in detections[0].cpu().numpy():   # move to CPU and numpy\n",
    "    x1, y1, x2, y2, conf, cls = det\n",
    "\n",
    "    # Convert to int\n",
    "    x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "\n",
    "    # Draw bounding box\n",
    "    cv2.rectangle(\n",
    "        img,\n",
    "        (x1, y1),\n",
    "        (x2, y2),\n",
    "        (0, 255, 0),   # green box\n",
    "        2              # box thickness\n",
    "    )\n",
    "\n",
    "    # Draw label text\n",
    "    label = f\"{int(cls)} {conf:.2f}\"\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        label,\n",
    "        (x1, y1 - 10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,            # font size\n",
    "        (0, 255, 0),    # text color\n",
    "        2               # thickness\n",
    "    )\n",
    "\n",
    "# Save or show result\n",
    "# cv2.imwrite(\"result.jpg\", img)\n",
    "cv2.imshow(\"result\", img); cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf42bd1-285b-4cd4-8165-ebf8ff441953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
