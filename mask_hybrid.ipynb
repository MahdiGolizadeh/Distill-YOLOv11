{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1abd46f6-910c-47a7-9f4c-6c88d18ccbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_masks_from_teacher_tal(t_mask, teacher_preds, mask_type=\"both\"):\n",
    "    \"\"\"\n",
    "    Generate:\n",
    "      1) Original TAL masks (hard binary per level)\n",
    "      2) Mask Pyramid (multi-scale OR fusion mask)\n",
    "\n",
    "    Args:\n",
    "        t_mask: [B, 8400] boolean mask from TAL.\n",
    "        teacher_preds: list of three prediction tensors:\n",
    "            [B, C, 80, 80], [B, C, 40, 40], [B, C, 20, 20]\n",
    "        mask_type: \n",
    "            \"original\" -> return only original masks\n",
    "            \"pyramid\"  -> return only pyramid masks\n",
    "            \"both\"     -> return both (default)\n",
    "\n",
    "    Returns:\n",
    "        Based on mask_type:\n",
    "            original_masks: [B,1,80,80], [B,1,40,40], [B,1,20,20]\n",
    "            pyramid_masks:  [B,1,80,80], [B,1,40,40], [B,1,20,20]\n",
    "    \"\"\"\n",
    "\n",
    "    batch = t_mask.shape[0]\n",
    "\n",
    "    # Extract spatial sizes dynamically\n",
    "    spatial_dims = [(p.shape[2], p.shape[3]) for p in teacher_preds]\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1. ORIGINAL HARD (BINARY) MASKS\n",
    "    # ---------------------------------------------------------\n",
    "    original_masks = []\n",
    "    start = 0\n",
    "\n",
    "    for h, w in spatial_dims:\n",
    "        N = h * w\n",
    "        end = start + N\n",
    "\n",
    "        # boolean -> float 0/1\n",
    "        mask = t_mask[:, start:end].float()\n",
    "        mask = mask.reshape(batch, 1, h, w)\n",
    "\n",
    "        original_masks.append(mask)\n",
    "        start = end\n",
    "\n",
    "    m3, m4, m5 = original_masks  # 80x80, 40x40, 20x20\n",
    "\n",
    "    # If user wants only original masks\n",
    "    if mask_type == \"original\":\n",
    "        return original_masks\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. MASK PYRAMID (MULTI-SCALE OR)\n",
    "    # ---------------------------------------------------------\n",
    "\n",
    "    # Step A: Upsample 40→80 and 20→80\n",
    "    m4_up = F.interpolate(m4, size=(80, 80), mode=\"nearest\")\n",
    "    m5_up = F.interpolate(m5, size=(80, 80), mode=\"nearest\")\n",
    "\n",
    "    # Ensure float domain (binary mix safety)\n",
    "    m3f = m3.float()\n",
    "    m4f = m4_up.float()\n",
    "    m5f = m5_up.float()\n",
    "\n",
    "    # Step B: OR fusion across scales\n",
    "    # OR rule: if any mask has 1 → output must be 1\n",
    "    pyramid_80 = torch.maximum(torch.maximum(m3f, m4f), m5f)\n",
    "    # Equivalent to OR: pyramid_80 = (m3f > 0) | (m4f > 0) | (m5f > 0)\n",
    "\n",
    "    # Step C: Downscale back to 40 and 20\n",
    "    pyramid_40 = F.interpolate(pyramid_80, size=(40, 40), mode=\"nearest\")\n",
    "    pyramid_20 = F.interpolate(pyramid_80, size=(20, 20), mode=\"nearest\")\n",
    "\n",
    "    pyramid_masks = [pyramid_80, pyramid_40, pyramid_20]\n",
    "\n",
    "    # If user wants only pyramid\n",
    "    if mask_type == \"pyramid\":\n",
    "        return pyramid_masks\n",
    "\n",
    "    # Else return both\n",
    "    return original_masks, pyramid_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983f8247-1c5d-4250-90ac-a6388691059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mask = t_mask = torch.rand(1, 8400) > 0.5 \n",
    "teacher_preds = [\n",
    "    torch.randn(1, 144, 80, 80, dtype=torch.float32),\n",
    "    torch.randn(1, 144, 40, 40, dtype=torch.float32),\n",
    "    torch.randn(1, 144, 20, 20, dtype=torch.float32)\n",
    "]\n",
    "student_preds = [\n",
    "    torch.randn(1, 144, 80, 80, dtype=torch.float32),\n",
    "    torch.randn(1, 144, 40, 40, dtype=torch.float32),\n",
    "    torch.randn(1, 144, 20, 20, dtype=torch.float32)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff172cda-d492-44ad-8bcc-e22541fa2b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "org, pyr = generate_masks_from_teacher_tal(t_mask, teacher_preds, mask_type=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9827b714-e1b5-4850-b02d-b61284e9bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def visualize_masks(original_masks, pyramid_masks, batch_idx=0):\n",
    "#     \"\"\"\n",
    "#     Plots:\n",
    "#       - Original masks: 80×80, 40×40, 20×20\n",
    "#       - Pyramid masks: 80×80, 40×40, 20×20\n",
    "\n",
    "#     Args:\n",
    "#         original_masks: list of 3 tensors [B,1,H,W]\n",
    "#         pyramid_masks:  list of 3 tensors [B,1,H,W]\n",
    "#         batch_idx: which sample to visualize\n",
    "#     \"\"\"\n",
    "\n",
    "#     titles = [\n",
    "#         \"Original Mask 80×80\", \"Original Mask 40×40\", \"Original Mask 20×20\",\n",
    "#         \"Pyramid Mask 80×80\", \"Pyramid Mask 40×40\", \"Pyramid Mask 20×20\"\n",
    "#     ]\n",
    "\n",
    "#     masks_to_show = [\n",
    "#         original_masks[0][batch_idx, 0].cpu().numpy(),\n",
    "#         original_masks[1][batch_idx, 0].cpu().numpy(),\n",
    "#         original_masks[2][batch_idx, 0].cpu().numpy(),\n",
    "#         pyramid_masks[0][batch_idx, 0].cpu().numpy(),\n",
    "#         pyramid_masks[1][batch_idx, 0].cpu().numpy(),\n",
    "#         pyramid_masks[2][batch_idx, 0].cpu().numpy(),\n",
    "#     ]\n",
    "\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "\n",
    "#     for i, (mask, title) in enumerate(zip(masks_to_show, titles)):\n",
    "#         plt.subplot(2, 3, i + 1)\n",
    "#         plt.imshow(mask, cmap=\"gray\", interpolation=\"nearest\")\n",
    "#         plt.title(title)\n",
    "#         plt.axis(\"off\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa4f09b-b760-4814-af3f-d78f11f406c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_masks(org, pyr, batch_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f5e9b0-11d4-40d9-944a-c544d69265c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def visualize_tensor_values_opencv(tensor, window_name=\"Tensor Values\", scale=40):\n",
    "#     \"\"\"\n",
    "#     Visualize a 2D tensor with OpenCV, showing each cell value as text.\n",
    "#     - tensor: torch.Tensor or numpy array, shape [H, W]\n",
    "#     - scale: pixel size for each cell\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Convert PyTorch → numpy\n",
    "#     if hasattr(tensor, \"cpu\"):\n",
    "#         tensor = tensor.cpu().numpy()\n",
    "\n",
    "#     H, W = tensor.shape\n",
    "\n",
    "#     # Create blank canvas\n",
    "#     img = np.zeros((H * scale, W * scale, 3), dtype=np.uint8)\n",
    "\n",
    "#     # Normalize tensor for coloring\n",
    "#     t_min, t_max = tensor.min(), tensor.max()\n",
    "#     if t_max - t_min == 0:\n",
    "#         norm = np.zeros_like(tensor)\n",
    "#     else:\n",
    "#         norm = (tensor - t_min) / (t_max - t_min)\n",
    "\n",
    "#     # Draw each cell\n",
    "#     for i in range(H):\n",
    "#         for j in range(W):\n",
    "#             # Pick color based on value\n",
    "#             intensity = int(norm[i, j] * 255)\n",
    "#             color = (intensity, intensity, 255)  # slight red tint\n",
    "\n",
    "#             # Draw rectangle\n",
    "#             cv2.rectangle(\n",
    "#                 img,\n",
    "#                 (j * scale, i * scale),\n",
    "#                 ((j + 1) * scale, (i + 1) * scale),\n",
    "#                 color,\n",
    "#                 thickness=-1\n",
    "#             )\n",
    "\n",
    "#             # Put value text\n",
    "#             val_str = f\"{tensor[i,j]:.2f}\" if tensor.dtype != bool else str(int(tensor[i,j]))\n",
    "#             cv2.putText(\n",
    "#                 img,\n",
    "#                 val_str,\n",
    "#                 (j * scale + 5, i * scale + scale - 5),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                 0.5,\n",
    "#                 (0, 0, 0),   # black text\n",
    "#                 1,\n",
    "#                 cv2.LINE_AA\n",
    "#             )\n",
    "\n",
    "#     cv2.imshow(window_name, img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0eaca74-fcc2-4a3e-a061-b219a48c4599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask contains non-binary values: False\n",
      "Mask contains non-binary values: False\n",
      "Mask contains non-binary values: False\n"
     ]
    }
   ],
   "source": [
    "for mask in pyr:\n",
    "    has_non_binary = torch.any((mask != 0) & (mask != 1))\n",
    "    print(\"Mask contains non-binary values:\", has_non_binary.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cc94ac7-d9bf-472f-b45c-eda61569b741",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 49\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# Create sample tensors\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     tensors \u001b[38;5;241m=\u001b[39m org[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m---> 49\u001b[0m     plot_binary_tensors_rich(tensors)\n",
      "Cell \u001b[1;32mIn[18], line 24\u001b[0m, in \u001b[0;36mplot_binary_tensors_rich\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m     16\u001b[0m table \u001b[38;5;241m=\u001b[39m Table(\n\u001b[0;32m     17\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinary Tensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     show_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     19\u001b[0m     box\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     20\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Add columns\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m     25\u001b[0m     table\u001b[38;5;241m.\u001b[39madd_column(style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m\"\u001b[39m, justify\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Add rows\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# First install: pip install rich numpy\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.text import Text\n",
    "import numpy as np\n",
    "\n",
    "def plot_binary_tensors_rich(tensors):\n",
    "    \"\"\"\n",
    "    Plot binary tensors using the Rich library for beautiful terminal output.\n",
    "    \"\"\"\n",
    "    console = Console()\n",
    "    \n",
    "    for i, tensor in enumerate(tensors):\n",
    "        # Create a table for each tensor\n",
    "        table = Table(\n",
    "            title=f\"Binary Tensor {i} (Shape: {tensor.shape})\",\n",
    "            show_header=False,\n",
    "            box=None,\n",
    "            padding=0\n",
    "        )\n",
    "        \n",
    "        # Add columns\n",
    "        for _ in range(tensor.shape[1]):\n",
    "            table.add_column(style=\"bold\", justify=\"center\")\n",
    "        \n",
    "        # Add rows\n",
    "        for row in tensor:\n",
    "            row_cells = []\n",
    "            for val in row:\n",
    "                val_int = int(val)\n",
    "                if val_int == 1:\n",
    "                    # Green background for 1s\n",
    "                    cell = Text(\" 1 \", style=\"black on green\")\n",
    "                else:\n",
    "                    # Red background for 0s\n",
    "                    cell = Text(\" 0 \", style=\"black on red\")\n",
    "                row_cells.append(cell)\n",
    "            table.add_row(*row_cells)\n",
    "        \n",
    "        console.print(table)\n",
    "        console.print()  # Empty line between tensors\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create sample tensors\n",
    "    tensors = org[0].squeeze()\n",
    "    \n",
    "    plot_binary_tensors_rich(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f28cef2-f02d-411c-bc74-4ee522d21684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 80, 80])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1c96b63-5915-4a1d-a5c6-0a49c8b6519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80x80 Tensor:\n",
      "██████████████████████████      ██████████████████████████████████████  ██████████  ████████████  ████████████████████████████  ████████    ██  ████████████████\n",
      "██████████████████████████  ██████████████████████████████████████████  ████████████████████████████████████████████████        ████████      ██████████████████\n",
      "████████████████████████████  ██████████████████  ██████████████████████████████████████████████████████████████      ██████████████████████████████████████████\n",
      "████████████████████████████    ██████████████████  ██  ██████████████  ████████    ██████████████████████████████      ████████████████████████████████  ██████\n",
      "████████  ██████████████████████████████████████████████████████    ████  ██████      ██████████████  ██████████████████  ██████████████    ██████████████  ████\n",
      "████████████  ████  ████████████████████████████████████████████    ████████████      ██████████████  ██████    ████████  ██████████████  ██████████████████████\n",
      "████████████  ██  ██████████████████████████████████████████████  ██████████    ████    ████    ████    ████████████████  ██████████████    ████████████████    \n",
      "██████████████    ████  ██████████████████████████████████████████  ████████  ██████    ████    ████  ██████████████████  ████  ████████    ██████████████████  \n",
      "████    ██████████████████████████████  ████████████████  ██████████████████████████████████████        ████████████████████    ████████████  ██████████████████\n",
      "████████████████████████████████████████████████████████████████████████████████████████████████  ██████████████████████████    ████████████  ██████████████████\n",
      "██████  ██████  ████████████████████████████████████████████████████████████████████████████████████████████████████████  ██████████████████████████████████████\n",
      "    ██  ██████  ██████████████████████████████████████████████████████████████████████████████████████████████████████████  ████████████████████████████████████\n",
      "██████        ████████████████████████  ██████████████████████████████████████████████████████████████████████████████████████████████████  ████████████████████\n",
      "████            ████  ██████████████████████████████████████████████████████████████████████████████████████████████████████████████      ██████████████████████\n",
      "████    ████████    ████████████████  ████████████████████████████████████████████████████████████      ████████████████████████    ████  ████  ████████████████\n",
      "████  ██████████  ██████████████████    ██████████████████████████████████████████████████████████  ██  ████████████████████████  ██    ██    ██████████████████\n",
      "████████████████████████████████████████████    ████████████████████████████    ██████████      ██████████████████████████████████████████████████████  ████████\n",
      "████████████████████████████████████████████      ██    ██████████████████████  ████████  ████  ████████████████████████████████████████  ████████████  ████████\n",
      "██████  ████████████████████████████  ██████    ██    ██████████████████████████████████    ██████████████████████████████████████████████████████  ████████████\n",
      "████    ████████████████████████  ██    ████    ██  ████████████████████████  ██████████  ██████████████████████████████████████████████████████  ██████████████\n",
      "  ██    ████████████  ██████████  ██    ██  ████████████████████████████████████████████████████████████████  ██  ██  ██████████████████████████████████████    \n",
      "██████  ████████████  ██████████    ██  ████████████████████████████████████████████████████████████████  ██████████    ████████████████████████████████████    \n",
      "██████████████████████████████████████████████████      ██████████████████████████████████████████████████████████████  ██████████████████████████████████████  \n",
      "████████████████████  ██████████████████████████  ██  ████████████████████████████████████████████████████████████████████████████████████████████████████    ██\n",
      "██    ██████████  ██████  ██████████    ██████████      ██████████████  ████████        ████████  ██    ████  ██████████████████    ██████████  ████  ██  ██████\n",
      "██████  ████████  ████████  ██████████  ████████      ██████████████    ██████████████  ██████████    ██████  ████████████████████  ██████      ████    ██    ██\n",
      "      ████████████████████████  ████    ████████████████████████████    ████████████  ██████████  ██████    ████████████████████████    ██████████      ████    \n",
      "██    ████████████████████████  ████  ██████████████████████████████████████████████    ██████████  ██████  ████████████████████    ████████████████████████    \n",
      "████████    ████████████████████████  ██    ██████    ████████████  ████████████████████████████████████████████████████  ████████████  ██████████████  ████████\n",
      "████████████████████████████████████          ██        ██████████████████████████████████████████████████████████████████  ██████████  ████████████    ████████\n",
      "████████████  ████      ████████████  ██  ██████████    ████████████████████████████████████████████████████████      ████████████████████████  ██  ████████████\n",
      "████████████████  ██    ██████████████████  ████████  ████████████████████████████████████████████████████████████      ████████████████████    ████████████████\n",
      "██████████  ██  ██████████████████      ████  ██████████████████████████████████████████████████  ██    ██  ██████████████  ████████████  ██████████████████████\n",
      "██████████  ██  ████████████████  ██  ██  ██    ████████████████████████████████████████████████  ██  ██████████████████    ██████████████  ████████████████████\n",
      "████████████████████████████████    ████████████████████████████████████████████████████████████████████████    ████  ████████████████████████  ████████████  ██\n",
      "██████████████████  ████████████    ████████████████████████████████████████████████████████████████████████  ██████  ██████████████████████    ████████████  ██\n",
      "  ██    ██████████████████████████  ████████████████████████████████████████████████████████████████  ██████████████████████████████  ██  ██████████    ████████\n",
      "██  ██  ████████████████████████  ████████  ██████████████████  ████████████████████████████████████  ██████  ████████████████████████      ████████    ████████\n",
      "██████████████████████████████████████  ████████████████████  ████████████████████████████████████████  ████████████████████████████████████████████  ██████████\n",
      "████████████████████████████████████  ██████████████████████████████████████████████████████████████████████████████████████████████████████████████  ██████████\n",
      "████████████████████    ████  ██████████████████████████    ██  ████████████████████████████████████  ████████████████  ████████  ████████████████████████  ████\n",
      "██████████████████████████████  ████████████████████████    ██  ██████████████████████████████████████  ████████████████████████    ████████████████        ████\n",
      "████████████████████    ██████████  ████████████████████████  ████████████████████████████████████████  ████████  ██████████████    ██████████████████████  ████\n",
      "████████████████████  ████████████  ████████████████████████    ████████████████████████████████████████████████    ██████████████  ████████████████████    ████\n",
      "████      ██    ████████████████████████████████████████████████  ████████████████████████████████████████████████████      ████████████    ████████████████████\n",
      "  ████    ██  ██████████████████████████    ████████████████████████████████████████████████████████████████████  ████    ██████████  ██    ████████████████████\n",
      "████    ██████████████  ██████████████████████    ██████████████████    ████████████████████████████████████████████  ██████  ██████████████    ████████████████\n",
      "██████████████████████  ████████████████      ██████████████████████  ██████████████████████  ██    ██████████████████  ████    ██████████  ██  ████████████████\n",
      "████████████████████    ██████████████████████████  ██  ████  ██████    ████    ██████████████████████████████████████████████████  ██  ████████  ████████  ████\n",
      "████████████████████    ██████████████████████████      ████          ██      ████████  ████████████████████████████████    ████████  ██████  ██████████████████\n",
      "██████████  ████████            ████████████████████████  ██████  ██  ████████████████████  ██████████████████████████████  ██      ████████████████████████████\n",
      "████████        ████    ██  ██  ████████████████████████    ██████  ██    ████████████  ████    ████████████████████████████  ██  ██    ████████████████████████\n",
      "██      ██████████████████  ████████    ██████████████████████████████████      ████████████████████████████  ██████████████  ██████████████████████    ████████\n",
      "  ████  ████████████      ██████  ████  ████████    ██████████████████████    ██████  ████████████████████████████████████  ████████████████████████    ████████\n",
      "    ████  ██  ████  ████    ████  ████████████████████████████████████████████████████  ████████████████████████████████████████████████████████████████████████\n",
      "    ██  ██  ██      ██████  ████    ████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████\n",
      "██████████████  ████  ████████████████████████████████████████████████████  ████████████████████████████████  ██████████  ██████████████████████████████████████\n",
      "████████████    ████    ██████████████████████████████████████████████████  ██████████████████████████████  ████████████    ████████  ██████████████████████████\n",
      "████████████████████    ██████████████████  ██  ██████████████████████████  ████████████████████████████████████████████████████████████████████    ████████████\n",
      "████████████████████    ██████████████████████  ██████████████████████████      ████████████████████████████████████████████████████████████████  ██████████████\n",
      "██████  ████████████████████████████    ████████  ████████████████████████████████████████████████████████████████████  ████████████    ████████████████████████\n",
      "██  ██  ████████████████    ████████  ████  ██      ██████████████████████████████████████████████████████████████████  ██████████████  ████████████████████████\n",
      "████████████████████████████  ██████  ██        ████  ██████████████████████████████████████████████████████████    ████████████  ██    ████████████████████████\n",
      "████████████████████████████████████    ████    ████  ██████████████████████████████████████████████████████████    ████████████████  ██████████████████████████\n",
      "██████████████████████████  ████████  ████████████████████  ██  ██████████████████████████████████  ██████████████████  ████████████████████████  ██  ██████████\n",
      "██████████████████████████  ████████  ██████    ████████  ██████████████████████████████████████    ██████████████████  ██████████████████████████████  ████████\n",
      "████████████████████████████████████████████████████████████████████████████    ██████████████████████████████████████  ████████████████████████████████████████\n",
      "██████████████████████████████████  ████████████████████████████████████████████████████████████  ████  ████████████  ██████████████████████████████████████████\n",
      "██████  ████████████████████████████████████████  ██    ████████    ██  ████  ██████████████████████████  ██    ████████████████    ████████    ████████████  ██\n",
      "████████████████████████████████████████████████  ██    ████████████    ██████████████████████████████████  ██  ████████████      ████████████  ██████████  ████\n",
      "██████  ████████████████████████████████████████████████████████    ██  ████    ██████████████████████████████████████████  ██████████  ████████      ████  ████\n",
      "████████████████████████████████████████████    ████████████████        ██████    ██████████████████████████████████████████  ████████  ██████████          ████\n",
      "████████████████████████████████████████████████████████████████████████████    ████████████████        ██████████████████  ████████████████████████████████████\n",
      "████████████████████████████████████████████████████████████████████████████    ████████████████████    ██████████████████  ████████████████████████████████████\n",
      "████████████████████████    ██████████████████████████████████████████████████████████████████████████████████  ████████████  ██████████        ██  ██  ████████\n",
      "██████████████████████████████  ██████████████████████████████████████████████████████████████████████████████  ████████████  ████████████  ██  ██    ██████████\n",
      "████  ████████████████████  ████████████████████  ██████████████████████████████████████  ██████████  ██  ██████████████████    ██  ████████  ██  ██  ██████████\n",
      "████  ████████████████████  ████████████████      ██    ████████████████████████████████  ██████    ██    ██████████████████      ██████████  ██  ██    ████████\n",
      "████████████████████████████    ████████████████████████████████████████████████████████████████████  ██████████████████    ██  ████████████    ██  ██████████  \n",
      "████████████████████████████  ████████████  ████████████████████████████████████████████████████████████  ██████████████████  ██  ██████████      ██████████    \n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_tensor_ascii(tensor, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Print tensor as ASCII art with '█' for 1 and ' ' for 0\n",
    "    \"\"\"\n",
    "    # Assuming tensor shape is [1, 1, H, W]\n",
    "    if len(tensor.shape) == 4:\n",
    "        data = tensor[0, 0]  # Extract the 2D data\n",
    "    else:\n",
    "        data = tensor\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        row = ''\n",
    "        for j in range(data.shape[1]):\n",
    "            if data[i, j] > threshold:\n",
    "                row += '██'\n",
    "            else:\n",
    "                row += '  '\n",
    "        print(row)\n",
    "\n",
    "# Example usage\n",
    "tensor_80x80 = pyr[0]  # Your 1x1x80x80 tensor\n",
    "print(\"80x80 Tensor:\")\n",
    "print_tensor_ascii(tensor_80x80)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fccec2-3a18-4e0e-a1f5-437a07fc6951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
